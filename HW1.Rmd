---
title: "MKT 500T"
author: "Sami Cheong"
date: "`r format(Sys.time(), '%b %d %Y')`"
output:
  pdf_document: default
  html_document:
    df_print: paged
subtitle: Spring 2018 HW1
geometry: left=3cm,right=3cm,top=2cm,bottom=2cm
---

# Projecting customer retention rates 
# Data
We are given the following customer retention data,starting with 1000 customers, but gradually decreasing over 12 years. For this assignment, we will use data from years 1-4:

```{r loadData, echo=FALSE, fig.align='center', fig.height=3, fig.width=4, message=FALSE, warning=FALSE}
library(dplyr)
library(knitr)
library(readxl)
library(kableExtra)
data<-read_excel('data/HW1 data.xlsx')
data$Year<-as.factor(data$Year)
names(data)<-c('Year','Regular','High_End')
sample.size<-5
kable(data[1:sample.size,])%>%kable_styling(full_width = FALSE)
```

to predict the following retention rates in the following periods:

``` {r,echo=FALSE,message=FALSE, warning=FALSE}
kable(data[(sample.size+1):nrow(data),])%>%kable_styling(full_width = FALSE)
```

Notice that the Regular segment has a significantly lower % of 'Alive' customers than the High End semengt:

``` {r plotData,echo=FALSE, fig.align='center', fig.height=2, fig.width=5, message=FALSE, warning=FALSE}
library(kableExtra)
library(ggplot2)
n<-1000
ggplot(data)+geom_point(aes(x=Year,y=Regular/n,color='Regular'),alpha=0.8)+
  geom_point(aes(x=Year,y=High_End/n,color='High End'),alpha=0.8)+
  labs(x='time period', y='# of remaining customers',title='   % of `Alive` customers overtime')+scale_colour_manual(values=c("purple","blue"))
#plot_ly(data,x=~Year,y=~High_End)

```
## Basic statistics
First, let's take a look at the churn rates and retention rates of each customer segment:

```{r massageData,fig.align='center',message=FALSE,warning=FALSE}
data[,'Churn_R']<- c(0, -diff(data$Regular))
data[,'Churn_H']<- c(0, -diff(data$High_End))
data[,'Ret_R']<- data$Regular/1000
data[,'Ret_H']<- data$High_End/1000
insamp.data<-data[1:sample.size,]
kable(insamp.data)
```

# Model
Based on this training data, we are interested in knowing the period $t$ in which a customer churns $P(T=t)$, with the following assumptions:

- $\theta$ is the probability that a customer witll 'flip' and switch brands

- $P(T=t|\theta)$ is the probability that a customer 'flip' at time $t$ given $\theta$, which follows the geometric distribution with density $f(t|\theta) = \theta(1-\theta)^t$

- $\theta$ follows a density function $g(\theta)$ characterized by $\Gamma(\alpha,\beta)$.

Since $P(T=t) = \int_{0}^{1} f(t|\theta) p(\theta) d\theta$, after some algebra we can deduce that $P(T=t)$ follows the shifted Beta Geometric Distribution, which is defined by the following: $$ P(T=t) =  \begin{cases}\frac{\alpha}{\alpha+\beta}  & \text{ for } t= 1, \\
\frac{\beta + t -1}{\alpha + \beta + t -1}P(T=t-1) & \text{ for } t =  2, 3, 4,...\end{cases}.$$

In here, $\alpha$ and $\beta$ are obtained by maximizing the log-likelihood function defined by $$ l(\alpha,\beta) = \sum_{t=1}^{4} c_t \ln(P(T=t|\theta)) + n_4 ln(P > 4|\theta),$$ where $c_i$ is the number of customers who churns at time $t$ and $n_4$ is the number of 'survivors' at the end of the $4^{th}$ season. 


```{r source_sBG, message=FALSE, warning=FALSE, include=FALSE}
source('code/sBG.R')
```

This parameter estimation procedure is implemented in R using the code provided in [`sBG.r`](https://github.com/samimath/Customer_Analytics/blob/master/code/sBG.R), presented as follows:

```{r, warning=FALSE,message=FALSE,echo}

# define 'survivors' for each segment
surv.R<-insamp.data$Regular[nrow(insamp.data)]
surv.H<-insamp.data$High_End[nrow(insamp.data)]

par.init=c(0.6,0.6)
# get optimized parameter values for Regular and High End segments:
result.reg = optim(par=par.init,fn=sBG.LL,
                    churn.data = insamp.data$Churn_R[2:nrow(insamp.data)], 
                    survivors = surv.R,control=list(fnscale=-1,reltol=1e-18))
par.final.reg = exp(result.reg$par)

result.high = optim(par=par.init,fn=sBG.LL,
                    churn.data = insamp.data$Churn_H[2:nrow(insamp.data)], 
                    survivors = surv.H,control=list(fnscale=-1,reltol=1e-18))
par.final.high = exp(result.high$par)

# compute density function values:
pmf.reg<-sBG.pmf(par.final.reg[1],par.final.reg[2],12)


pmf.high<-sBG.pmf(par.final.high[1],par.final.high[2],12)

# compute log-likelihood valuse:
LL.reg<-sBG.LL(par.final.reg,insamp.data$Churn_R[2:nrow(insamp.data)],
               surv.R,debug.flag=F)

LL.high<-sBG.LL(par.final.high,insamp.data$Churn_H[2:nrow(insamp.data)],
                surv.H,debug.flag=F)

# collect values:
LL<-c(LL.reg,LL.high)

```

# Result
Using 4 years of training data, we obtained the following best estimates for $\alpha$ and $\beta.$ Notice that estimates for the High End segment has a worse likelihood value than the Regular segment, this suggests that the High End model may not have as good a fit compared to the Regular one. 

```{r, echo=FALSE}

par.final<-rbind(par.final.reg,par.final.high)
par.final<-cbind(par.final,LL)
colnames(par.final)<-c('alpha','beta','log-likelihood')
row.names(par.final)<-c('Regular','High End')
kable(par.final,col.names =colnames(par.final) )
```

Putting it all together:


``` {r}
data[,'Forecast_R']<-round(c(1,1-cumsum(pmf.reg)),2)
data[,'Forecast_H']<-round(c(1,1-cumsum(pmf.high)),2)

data[,'APE_R']<-round(abs(data$Ret_R-data$Forecast_R)/data$Ret_R,2)

data[,'APE_H']<-round(abs(data$Ret_H-data$Forecast_H)/data$Ret_H,2)
```





``` {r echo=FALSE, fig.align='center', fig.height=3, fig.width=5, message=FALSE, warning=FALSE}


n<-1000
ggplot(data)+geom_point(aes(x=Year,y=Regular/n,color='Actual'),alpha=0.8)+
  geom_point(aes(x=Year,y=Forecast_R,color='Forecast'),alpha=0.8)+scale_colour_manual(values=c("blue","cyan"))+
  labs(x='time period', y='# of remaining customers',title='Retention rates (actual vs forecast)\n for Regular segment')


ggplot(data)+geom_point(aes(x=Year,y=High_End/n,color='Actual'),alpha=0.8)+
  geom_point(aes(x=Year,y=Forecast_H,color='Forecast'),alpha=0.8)+scale_colour_manual(values=c("purple","magenta"))+
  labs(x='time period', y='# of remaining customers',title='Retention rates (actual vs forecast)\n for High End segment')



```

```{r,echo=FALSE,fig.height=2.5}
kable(data[2:nrow(data),c('Year','Ret_R','Forecast_R','APE_R','Ret_H','Forecast_H','APE_H')])
insample.MAPE<-c(mean(data$APE_R[2:sample.size]),mean(data$APE_H[2:sample.size]))
outsample.MAPE<-c(mean(data$APE_R[(sample.size+1):nrow(data)]),mean(data$APE_H[(sample.size+1):nrow(data)]))
```

## Comparing model trained on 4 years vs 7 years of data:

In here, we calculate the in and out-of-sample average percent error for model trained with 4 years. While both in-sample MAPE is relatively small (0.5 % and 1% respecitvely), the out-of-sample MAPE's are much higher (6% and 13% respecitvely). Repeating the same procedure using 7 years of data instead gives the following:

```{r, echo=FALSE}
High_End_7<-c(0.017,0.028)
Regular_7<-c(0.011,0.015)
MAPE<-rbind(insample.MAPE,outsample.MAPE)
MAPE<-cbind(MAPE,Regular_7,High_End_7)
kable(MAPE,col.names = c('Regular','High End','Regular (7 years data)','High End (7 years data)'))

```

Interestingly, MAPE's from models trained with 4 years of data were actually lower when we looking at in-sample data. This suggests that they provide a better fit for the data, but ultimately the models are not as predictive compared to those that used 7 years of data.




### How did the training data change the underlying distribution for $g(\theta)$?

Another interesting observation is that, comparing to the example for High End data set (where $\alpha = 0.668$ and $\beta = 3.806$), both $\alpha$ and $\beta$ here are estimated to be higher when using less traiing data. This changes the density quite a bit as it moves the curve for $g(\theta)$ to an entirely different quadrant, linking that to the MAPE, we see that the discrepensies between the High End models trianed are much higher compared to those using the data from the Regular segment. 


```{r,fig.height=2,echo=FALSE,fig.align='center',message=FALSE,warning=FALSE}
theta<-seq(from=0,to=1,by=0.01)
beta7_high<-dbeta(theta,0.668083,3.806053)
beta4_high<-dbeta(theta,par.final.high[1],par.final.high[2])

beta7_reg<-dbeta(theta,0.704,1.182)
beta4_reg<-dbeta(theta,par.final.reg[1],par.final.reg[2])


compare.plt<-cbind(theta,beta7_high,beta4_high, beta7_reg,beta4_reg)
compare.plt<-data.frame(compare.plt)
ggplot(compare.plt)+geom_line(aes(theta,beta7_high,color='High End model with 7 years of data'))+
  geom_line(aes(theta,beta4_high,color='High End model  with 4 years of data'))+labs(y='frequency')

ggplot(compare.plt)+geom_line(aes(theta,beta7_reg,color='Regular model with 7 years of data'))+
  geom_line(aes(theta,beta4_reg,color='Regular model with 4 years of data'))+labs(y='frequency')
#grid.arrange(plt7, plt4, ncol=2)
```

## Conclusion

In this assignment, we investigated the following:

- Analyzed two sets of customer churn data over 12 years
- Applied the shifted Beta-Geometric distribution to model the probability of churn ($\theta$)
- Estimated the parameters ($\alpha, \beta$) that govern $\theta$ using maximum-likelihood estimation
- Compared model performance using 4 years of trianing data vs 7 years of training data

